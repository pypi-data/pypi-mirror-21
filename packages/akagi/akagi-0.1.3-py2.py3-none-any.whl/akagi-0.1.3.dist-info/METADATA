Metadata-Version: 2.0
Name: akagi
Version: 0.1.3
Summary: Codenize your data sources
Home-page: https://github.com/ayemos/akagi
Author: Yuichiro Someya
Author-email: ayemos.y@gmail.com
License: MIT license
Keywords: akagi
Platform: UNKNOWN
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Requires-Dist: boto3 (>=1.4.4)
Requires-Dist: numpy (>=1.12)
Requires-Dist: tqdm (>=4.11)

==========
akagi
==========

.. image:: https://img.shields.io/pypi/v/akagi.svg
  :target: https://pypi.python.org/pypi/akagi

.. image:: https://img.shields.io/travis/ayemos/akagi.svg
  :target: https://travis-ci.org/ayemos/akagi

.. image:: https://readthedocs.org/projects/akagi/badge/?version=latest
  :target: https://akagi.readthedocs.io/en/latest/?badge=latest

.. image:: https://pyup.io/repos/github/ayemos/akagi/shield.svg
  :target: https://pyup.io/repos/github/ayemos/akagi/


###########
akagi
###########

* Free software: MIT license

---------
Features
---------

akagi supports *iter* and *save* interface for various datasources such as Amazon Redshift, Amazon S3 (more in future).

-------------
Installation
-------------

Install via pip::

  pip install akagi

or from source::

  $ git clone https://github.com/ayemos/akagi akagi
  $ cd akagi
  $ python setup.py install

--------
Example
--------

++++++++++++++++++
RedshiftDatasource
++++++++++++++++++

.. code:: python

  ds = RedshiftDatasource.for_query(
          'log-redshift-unload.ap-northeast-1', # S3 Bucket for intermediate storage
          'select * from (select user_id, path from logs.imp limit 10000)', # Your Query here
          'logs', # schema
          'imp' # table (Those two are used to generate unique prefix for S3 object (e.g. logs/imp/20170312_081527)
          )

  ds.save('./akagi_test') # save results to local

  for d in ds:
      print(d) # iterate on result

++++++++++++
S3Datasource
++++++++++++


.. code:: python

  ds = S3Datasource.for_prefix(
          'image-data.ap-northeast-1',
          'data/image_net/zebra',
          FileFormat.BINARY
          )


--------
Credits
--------

This package was created with `Cookiecutter <https://github.com/audreyr/cookiecutter>`_ and the
`audreyr/cookiecutter-pypackage <https://github.com/audreyr/cookiecutter-pypackage>`_ project template.


