{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMRQ Model Selection\n",
    "We use cross-validation and the generalized matrix Rayleigh quotient (GMRQ) for selecting MSM hyperparameters. The GMRQ is a criterion which \"scores\" how well the MSM eigenvectors generated on the training dataset serve as slow coordinates for the test dataset [1].\n",
    "\n",
    "[1] McGibbon, R. T. and V. S. Pande, [Variational cross-validation of slow dynamical modes in molecular kinetics](http://arxiv.org/abs/1407.8083) (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "This example uses the doublewell dataset, which consists of ten trajectories in 1D with $x \\in [-\\pi, \\pi]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msmbuilder.example_datasets import DoubleWell\n",
    "trajectories = DoubleWell(random_state=0).get().trajectories\n",
    "# sub-sample by taking only every 100th data point in each trajectory.\n",
    "trajectories = [t[::100] for t in trajectories]\n",
    "print([t.shape for t in trajectories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up pipeline\n",
    "The `Pipeline` is a way of connecting together multiple estimators, so that we can create a custom model that\n",
    "performs a sequence of steps. This model is relatively simple. It will first discretize the trajectory data\n",
    "onto an evenly spaced grid between $-\\pi$ and $\\pi$, and then build an MSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from msmbuilder.cluster import NDGrid\n",
    "from msmbuilder.msm import MarkovStateModel\n",
    "import numpy as np\n",
    "\n",
    "model = Pipeline([\n",
    "    ('grid', NDGrid(min=-np.pi, max=np.pi)),\n",
    "    ('msm', MarkovStateModel(n_timescales=1, lag_time=1, reversible_type='transpose', verbose=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "To get an accurate indication of how well our MSMs are doing at finding the dominant eigenfunctions of our stochastic process, we need to consider the tendency of statistical models to overfit their training data. Our MSMs might build transition matrices which fit the noise in training data as opposed to the underlying signal. One way to combat overfitting in a data-efficient way is with cross validation. This example uses 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "n_states = [5, 10, 25, 50, 100, 200, 500, 750]\n",
    "cv = KFold(len(trajectories), n_folds=5)\n",
    "results = []\n",
    "\n",
    "for n in n_states:\n",
    "    model.set_params(grid__n_bins_per_feature=n)\n",
    "    for fold, (train_index, test_index) in enumerate(cv):\n",
    "        train_data = [trajectories[i] for i in train_index]\n",
    "        test_data = [trajectories[i] for i in test_index]\n",
    "\n",
    "        # fit model with a subset of the data (training data).\n",
    "        # then we'll score it on both this training data (which\n",
    "        # will give an overly-rosy picture of its performance)\n",
    "        # and on the test data.\n",
    "        model.fit(train_data)\n",
    "        train_score = model.score(train_data)\n",
    "        test_score = model.score(test_data)\n",
    "\n",
    "        results.append({\n",
    "            'train_score': train_score,\n",
    "            'test_score': test_score,\n",
    "            'n_states': n,\n",
    "            'fold': fold})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas to query our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(results)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the average for each fold\n",
    "We use the median for its tolerance to outliers. Mean works too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgs = (results\n",
    "         .groupby('n_states')\n",
    "         .aggregate(np.median)\n",
    "         .drop('fold', axis=1))\n",
    "avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_n = avgs['test_score'].argmax()\n",
    "best_score = avgs.loc[best_n, 'test_score']\n",
    "print(best_n, \"states gives the best score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "This plot is very similar to figure 1 from [McGibbon and Pande](http://arxiv.org/abs/1407.8083). It shows\n",
    "that the performance on the training set keeps going up as we increase the number of states (with the\n",
    "amount of data fixed), whereas the test performance peaks and then starts going down.\n",
    "\n",
    "We should pick the model with the highest average test set performance. In this example, we're only choosing over\n",
    "the number of MSMs states, but this method can also be used to evaluate the clustering method and any pre-processing\n",
    "like tICA.\n",
    "\n",
    "However, you do need to fix the number of dynamical processes to \"score\" (this is the `n_timescales` attribute for `MarkovStateModel`), as well as the lag time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(results['n_states'], results['train_score'], c='b', lw=0, label=None)\n",
    "plt.scatter(results['n_states'], results['test_score'],  c='r', lw=0, label=None)\n",
    "\n",
    "plt.plot(avgs.index, avgs['test_score'], c='r', lw=2, label='Mean test')\n",
    "plt.plot(avgs.index, avgs['train_score'], c='b', lw=2, label='Mean train')\n",
    "\n",
    "plt.plot(best_n, best_score, c='w', \n",
    "         marker='*', ms=20, label='{} states'.format(best_n))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim((min(n_states)*.5, max(n_states)*5))\n",
    "plt.ylabel('Generalized Matrix Rayleigh Quotient (Score)')\n",
    "plt.xlabel('Number of states')\n",
    "\n",
    "plt.legend(loc='lower right', numpoints=1)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
